#!/usr/bin/env python3
"""
Bio-Agent æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

å°†é€’é€ç³»ç»Ÿå’Œå¾®ç”Ÿç‰© CSV æ•°æ®å¯¼å…¥ MongoDB

ä½¿ç”¨æ–¹æ³•:
    cd backend
    python scripts/init_database.py [--dry-run] [--skip-md-check]

æ•°æ®æº:
    - é€’é€ç³»ç»Ÿæå–_export_2026-01-27 (1).csv â†’ biomaterials collection (category: delivery_system)
    - å¾®ç”Ÿç‰©æå–_export_2026-01-29 (1).csv â†’ biomaterials collection (category: microbe)
    â†’ documents collection (å»é‡åˆå¹¶çš„è®ºæ–‡ä¿¡æ¯)
"""

import csv
import json
import asyncio
import sys
import argparse
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from motor.motor_asyncio import AsyncIOMotorClient
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv(Path(__file__).parent.parent / ".env")

# =============================================
# é…ç½®
# =============================================
MONGODB_URL = os.getenv("MONGODB_URL", "mongodb://localhost:27017")
DATABASE_NAME = os.getenv("MONGODB_DB_NAME", "biomedical_platform")

# CSV æ–‡ä»¶è·¯å¾„ (ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•)
PROJECT_ROOT = Path(__file__).parent.parent.parent
DELIVERY_CSV = PROJECT_ROOT / "é€’é€ç³»ç»Ÿæå–_export_2026-01-27 (1).csv"
MICROBE_CSV = PROJECT_ROOT / "å¾®ç”Ÿç‰©æå–_export_2026-01-29 (1).csv"


class DatabaseInitializer:
    """æ•°æ®åº“åˆå§‹åŒ–å™¨"""
    
    def __init__(self, mongo_uri: str, db_name: str, dry_run: bool = False):
        self.mongo_uri = mongo_uri
        self.db_name = db_name
        self.dry_run = dry_run
        self.client = None
        self.db = None
        
        # ç»Ÿè®¡
        self.stats = {
            "documents_total": 0,
            "biomaterials_delivery": 0,
            "biomaterials_microbe": 0,
            "errors": 0,
        }
    
    async def connect(self):
        """è¿æ¥ MongoDB"""
        self.client = AsyncIOMotorClient(self.mongo_uri)
        self.db = self.client[self.db_name]
        print(f"âœ“ Connected to MongoDB: {self.mongo_uri}")
        print(f"  Database: {self.db_name}")
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.client:
            self.client.close()
    
    def parse_csv(self, csv_path: Path) -> List[Dict[str, Any]]:
        """è§£æ CSV æ–‡ä»¶"""
        records = []
        
        # å¢åŠ å­—æ®µå¤§å°é™åˆ¶ï¼Œé˜²æ­¢å¤§ JSON å­—æ®µæŠ¥é”™
        csv.field_size_limit(sys.maxsize)
        
        with open(csv_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # è§£æ features JSON (ç¬¬6åˆ—)
                features_str = row.get('features', '{}')
                try:
                    features = json.loads(features_str)
                except json.JSONDecodeError:
                    features = {}
                
                records.append({
                    "paper_id": row.get("paper_id", ""),
                    "title": row.get("title", ""),
                    "authors": row.get("authors", ""),
                    "journal": row.get("journal", ""),
                    "publish_year": int(row.get("publish_year", 0)) if row.get("publish_year", "").isdigit() else 0,
                    "features": features,
                })
        return records
    
    async def create_indexes(self):
        """åˆ›å»ºæ•°æ®åº“ç´¢å¼•ï¼ˆä¸ºæ‰€æœ‰é›†åˆåˆ›å»ºå¿…è¦ç´¢å¼•ï¼‰"""
        print("\nğŸ“Š Creating indexes for all collections...")
        
        if self.dry_run:
            print("   Skipped (dry run)")
            return
        
        # =============================================
        # æ ¸å¿ƒä¸šåŠ¡æ•°æ®è¡¨
        # =============================================
        
        # documents collection - è®ºæ–‡æ–‡çŒ®
        docs = self.db["documents"]
        await docs.create_index("paper_id", unique=True)
        await docs.create_index("source_tables")
        await docs.create_index([("title", "text"), ("authors", "text")])
        print("   âœ“ documents")
        
        # biomaterials collection - ç”Ÿç‰©ææ–™
        bio = self.db["biomaterials"]
        await bio.create_index("id", unique=True)
        await bio.create_index("category")
        await bio.create_index("subcategory")
        await bio.create_index("paper_id")
        await bio.create_index("name")
        await bio.create_index([("name", "text"), ("paper_titles", "text")])
        print("   âœ“ biomaterials")
        
        # paper_tags collection - è®ºæ–‡æ ‡ç­¾
        tags = self.db["paper_tags"]
        await tags.create_index("paper_id", unique=True)
        await tags.create_index("l1")
        await tags.create_index("l2")
        await tags.create_index("classification")
        print("   âœ“ paper_tags")
        
        # atps_records collection - ATPS è®°å½•
        atps = self.db["atps_records"]
        await atps.create_index("polymer1")
        await atps.create_index("polymer2")
        await atps.create_index([("polymer1", 1), ("polymer2", 1)])
        print("   âœ“ atps_records")
        
        # assemblies collection - ç»„è£…ä½“
        assemblies = self.db["assemblies"]
        await assemblies.create_index("system_id", unique=True)
        await assemblies.create_index("category")
        await assemblies.create_index("paper_id")
        print("   âœ“ assemblies")
        
        # =============================================
        # ç”¨æˆ·ä¸è®¤è¯
        # =============================================
        
        # users collection - ç”¨æˆ·
        users = self.db["users"]
        await users.create_index("username", unique=True)
        await users.create_index("email", unique=True)
        await users.create_index("role")
        await users.create_index("is_active")
        print("   âœ“ users")
        
        # =============================================
        # å¯¹è¯ç®¡ç†
        # =============================================
        
        # conversations collection - å¯¹è¯
        convos = self.db["conversations"]
        await convos.create_index("id", unique=True)
        await convos.create_index("user_id")
        await convos.create_index("created_at")
        await convos.create_index("updated_at")
        await convos.create_index([("user_id", 1), ("created_at", -1)])
        await convos.create_index([("user_id", 1), ("updated_at", -1)])
        print("   âœ“ conversations")
        
        # messages collection - æ¶ˆæ¯
        msgs = self.db["messages"]
        await msgs.create_index("id", unique=True)
        await msgs.create_index("conversation_id")
        await msgs.create_index("timestamp")
        await msgs.create_index([("conversation_id", 1), ("timestamp", 1)])
        print("   âœ“ messages")
        
        # =============================================
        # Agent ä¸ LLM é…ç½®
        # =============================================
        
        # agents collection - Agent é…ç½®
        agents = self.db["agents"]
        await agents.create_index("id", unique=True)
        await agents.create_index("name")
        await agents.create_index("is_active")
        await agents.create_index("created_at")
        print("   âœ“ agents")
        
        # llm_providers collection - LLM æä¾›å•†
        providers = self.db["llm_providers"]
        await providers.create_index("id", unique=True)
        await providers.create_index("name")
        await providers.create_index("provider_type")
        await providers.create_index("is_active")
        print("   âœ“ llm_providers")
        
        # prompts collection - æç¤ºè¯æ¨¡æ¿
        prompts = self.db["prompts"]
        await prompts.create_index("id", unique=True)
        await prompts.create_index("name")
        await prompts.create_index("category")
        await prompts.create_index("is_active")
        print("   âœ“ prompts")
        
        # =============================================
        # MCP é…ç½®
        # =============================================
        
        # mcp_configs collection - MCP å…¨å±€é…ç½®
        mcp_configs = self.db["mcp_configs"]
        await mcp_configs.create_index("id", unique=True)
        await mcp_configs.create_index("name")
        print("   âœ“ mcp_configs")
        
        # mcp_servers collection - MCP æœåŠ¡å™¨
        mcp_servers = self.db["mcp_servers"]
        await mcp_servers.create_index("id", unique=True)
        await mcp_servers.create_index("name")
        await mcp_servers.create_index("is_active")
        print("   âœ“ mcp_servers")
        
        # mcp_tools collection - MCP å·¥å…·
        mcp_tools = self.db["mcp_tools"]
        await mcp_tools.create_index("id", unique=True)
        await mcp_tools.create_index("server_id")
        await mcp_tools.create_index("name")
        await mcp_tools.create_index("is_enabled")
        print("   âœ“ mcp_tools")
        
        # =============================================
        # çŸ¥è¯†åº“ä¸æŠ€èƒ½
        # =============================================
        
        # knowledge_bases collection - çŸ¥è¯†åº“
        kb = self.db["knowledge_bases"]
        await kb.create_index("id", unique=True)
        await kb.create_index("name")
        await kb.create_index("category")
        await kb.create_index("created_at")
        print("   âœ“ knowledge_bases")
        
        # skills collection - æŠ€èƒ½
        skills = self.db["skills"]
        await skills.create_index("id", unique=True)
        await skills.create_index("name")
        await skills.create_index("category")
        await skills.create_index("is_active")
        print("   âœ“ skills")
        
        # =============================================
        # æ–‡ä»¶ä¸ä»»åŠ¡
        # =============================================
        
        # files collection - æ–‡ä»¶å­˜å‚¨
        files = self.db["files"]
        await files.create_index("id", unique=True)
        await files.create_index("filename")
        await files.create_index("user_id")
        await files.create_index("created_at")
        print("   âœ“ files")
        
        # ocr_tasks collection - OCR ä»»åŠ¡
        ocr = self.db["ocr_tasks"]
        await ocr.create_index("id", unique=True)
        await ocr.create_index("file_id")
        await ocr.create_index("status")
        await ocr.create_index("created_at")
        print("   âœ“ ocr_tasks")
        
        # playground_sessions collection - Playground ä¼šè¯
        playground = self.db["playground_sessions"]
        await playground.create_index("id", unique=True)
        await playground.create_index("user_id")
        await playground.create_index("created_at")
        print("   âœ“ playground_sessions")
        
        print("\n   âœ“ All 18 collections initialized with indexes")
    
    async def import_documents(self, delivery_records: List[Dict], microbe_records: List[Dict]):
        """å¯¼å…¥æ–‡çŒ®è¡¨ (å»é‡åˆå¹¶)"""
        print("\nğŸ“š Importing documents...")
        
        # åˆå¹¶å¹¶å»é‡
        papers: Dict[str, Dict] = {}
        
        for record in delivery_records:
            pid = record["paper_id"]
            if not pid:
                continue
            if pid not in papers:
                papers[pid] = {
                    "paper_id": pid,
                    "title": record["title"],
                    "authors": record["authors"],
                    "journal": record["journal"],
                    "publish_year": record["publish_year"],
                    "source_tables": ["delivery"],
                    "created_at": datetime.now(),
                }
            else:
                if "delivery" not in papers[pid]["source_tables"]:
                    papers[pid]["source_tables"].append("delivery")
        
        for record in microbe_records:
            pid = record["paper_id"]
            if not pid:
                continue
            if pid not in papers:
                papers[pid] = {
                    "paper_id": pid,
                    "title": record["title"],
                    "authors": record["authors"],
                    "journal": record["journal"],
                    "publish_year": record["publish_year"],
                    "source_tables": ["microbe"],
                    "created_at": datetime.now(),
                }
            else:
                if "microbe" not in papers[pid]["source_tables"]:
                    papers[pid]["source_tables"].append("microbe")
        
        print(f"   Unique papers: {len(papers)}")
        
        if not self.dry_run and papers:
            docs_collection = self.db["documents"]
            await docs_collection.delete_many({})
            
            # æ‰¹é‡æ’å…¥
            batch_size = 1000
            paper_list = list(papers.values())
            for i in range(0, len(paper_list), batch_size):
                batch = paper_list[i:i + batch_size]
                await docs_collection.insert_many(batch)
                print(f"   Inserted batch: {i + len(batch)}/{len(paper_list)}")
        
        self.stats["documents_total"] = len(papers)
        print(f"   âœ“ Imported {len(papers)} documents")
        return papers
    
    async def import_biomaterials(self, delivery_records: List[Dict], microbe_records: List[Dict]):
        """å¯¼å…¥ç”Ÿç‰©ææ–™è¡¨"""
        print("\nğŸ§¬ Importing biomaterials...")
        
        biomaterials = []
        seen_ids = set()
        
        # å¤„ç†é€’é€ç³»ç»Ÿ
        print("   Processing delivery systems...")
        for record in delivery_records:
            features = record.get("features", {})
            assemblies = features.get("assemblies", [])
            
            for asm in assemblies:
                system_id = asm.get("system_id", "")
                if not system_id or system_id in seen_ids:
                    continue
                seen_ids.add(system_id)
                
                composition = asm.get("composition", {})
                func_perf = asm.get("functional_performance", {})
                bio_impact = asm.get("biological_impact_on_host", {})
                
                biomaterials.append({
                    "id": system_id,
                    "name": composition.get("material_name", system_id),
                    "category": "delivery_system",
                    "subcategory": asm.get("system_category", "unknown"),
                    "paper_id": record["paper_id"],
                    "paper_titles": [record["title"]],
                    "source_doc_ids": [record["paper_id"]],
                    "paper_count": 1,
                    "composition": composition,
                    "functional_performance": func_perf,
                    "biological_impact": bio_impact,
                    "payload": composition.get("payload_name"),
                    "loading_mode": composition.get("loading_mode"),
                    "release_kinetics": func_perf.get("release_kinetics"),
                    "raw_data": asm,
                    "created_at": datetime.now(),
                })
        
        self.stats["biomaterials_delivery"] = len(biomaterials)
        print(f"   Delivery systems: {len(biomaterials)}")
        
        # å¤„ç†å¾®ç”Ÿç‰©
        print("   Processing microbes...")
        microbe_count = 0
        for record in microbe_records:
            features = record.get("features", {})
            microbes = features.get("microbes", [])
            
            for mic in microbes:
                identity = mic.get("identity", {})
                std_name = mic.get("standardized_name", "")
                if not std_name or std_name in seen_ids:
                    continue
                seen_ids.add(std_name)
                
                chassis = mic.get("chassis_and_growth", {})
                effector = mic.get("effector_modules", {})
                sensing = mic.get("sensing_modules", {})
                biosafety = mic.get("biosafety_and_containment", {})
                
                biomaterials.append({
                    "id": std_name,
                    "name": std_name,
                    "category": "microbe",
                    "subcategory": identity.get("type", "unknown"),
                    "paper_id": record["paper_id"],
                    "paper_titles": [record["title"]],
                    "source_doc_ids": [record["paper_id"]],
                    "paper_count": 1,
                    "identity": identity,
                    "chassis_and_growth": chassis,
                    "effector_modules": effector,
                    "sensing_modules": sensing,
                    "biosafety": biosafety,
                    "genus": identity.get("genus"),
                    "species": identity.get("species"),
                    "strain": identity.get("strain"),
                    "is_engineered": identity.get("is_engineered"),
                    "raw_data": mic,
                    "created_at": datetime.now(),
                })
                microbe_count += 1
        
        self.stats["biomaterials_microbe"] = microbe_count
        print(f"   Microbes: {microbe_count}")
        
        # å†™å…¥æ•°æ®åº“
        if not self.dry_run and biomaterials:
            bio_collection = self.db["biomaterials"]
            await bio_collection.delete_many({})
            
            batch_size = 1000
            for i in range(0, len(biomaterials), batch_size):
                batch = biomaterials[i:i + batch_size]
                await bio_collection.insert_many(batch)
                print(f"   Inserted batch: {i + len(batch)}/{len(biomaterials)}")
        
        total = self.stats["biomaterials_delivery"] + self.stats["biomaterials_microbe"]
        print(f"   âœ“ Imported {total} biomaterials total")
        return biomaterials
    
    async def create_default_admin(self):
        """åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·"""
        print("\nğŸ‘¤ Creating default admin user...")
        
        if self.dry_run:
            print("   Skipped (dry run)")
            return
        
        from passlib.context import CryptContext
        pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
        
        users = self.db["users"]
        existing = await users.find_one({"username": "admin"})
        
        if existing:
            print("   Admin user already exists, skipping")
            return
        
        admin_user = {
            "id": "admin-001",
            "username": "admin",
            "email": "admin@example.com",
            "hashed_password": pwd_context.hash("admin123"),
            "full_name": "ç³»ç»Ÿç®¡ç†å‘˜",
            "role": "admin",
            "is_active": True,
            "created_at": datetime.now(),
        }
        
        await users.insert_one(admin_user)
        print("   âœ“ Default admin created (username: admin, password: admin123)")
        print("   âš ï¸  è¯·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç«‹å³ä¿®æ”¹é»˜è®¤å¯†ç !")
    
    async def run(self):
        """æ‰§è¡Œå®Œæ•´åˆå§‹åŒ–æµç¨‹"""
        print("=" * 60)
        print("Bio-Agent Database Initialization")
        print("=" * 60)
        print(f"MongoDB: {self.mongo_uri}")
        print(f"Database: {self.db_name}")
        print(f"Dry Run: {self.dry_run}")
        print()
        
        # æ£€æŸ¥ CSV æ–‡ä»¶
        print("ğŸ“ Checking data files...")
        if not DELIVERY_CSV.exists():
            print(f"   âš ï¸  Delivery CSV not found: {DELIVERY_CSV}")
            print("   Skipping delivery data import")
            delivery_records = []
        else:
            print(f"   âœ“ Delivery CSV: {DELIVERY_CSV.stat().st_size / (1024*1024):.1f} MB")
            delivery_records = self.parse_csv(DELIVERY_CSV)
            print(f"     Parsed: {len(delivery_records)} rows")
        
        if not MICROBE_CSV.exists():
            print(f"   âš ï¸  Microbe CSV not found: {MICROBE_CSV}")
            print("   Skipping microbe data import")
            microbe_records = []
        else:
            print(f"   âœ“ Microbe CSV: {MICROBE_CSV.stat().st_size / (1024*1024):.1f} MB")
            microbe_records = self.parse_csv(MICROBE_CSV)
            print(f"     Parsed: {len(microbe_records)} rows")
        
        await self.connect()
        
        try:
            # å¯¼å…¥æ•°æ®
            if delivery_records or microbe_records:
                await self.import_documents(delivery_records, microbe_records)
                await self.import_biomaterials(delivery_records, microbe_records)
            
            # åˆ›å»ºç´¢å¼•
            await self.create_indexes()
            
            # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜
            await self.create_default_admin()
            
            # æ‰“å°ç»Ÿè®¡
            print("\n" + "=" * 60)
            print("ğŸ“Š Summary")
            print("=" * 60)
            print(f"Documents:        {self.stats['documents_total']}")
            print(f"Biomaterials:     {self.stats['biomaterials_delivery'] + self.stats['biomaterials_microbe']}")
            print(f"  - Delivery:     {self.stats['biomaterials_delivery']}")
            print(f"  - Microbes:     {self.stats['biomaterials_microbe']}")
            print()
            
            if self.dry_run:
                print("âš ï¸  This was a dry run. No data was actually written.")
            else:
                print("âœ… Database initialization completed successfully!")
            
        finally:
            await self.close()


async def main():
    parser = argparse.ArgumentParser(description="Initialize Bio-Agent database")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Parse files and show statistics without importing"
    )
    args = parser.parse_args()
    
    initializer = DatabaseInitializer(MONGODB_URL, DATABASE_NAME, dry_run=args.dry_run)
    await initializer.run()


if __name__ == "__main__":
    asyncio.run(main())
