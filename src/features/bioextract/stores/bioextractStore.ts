/**
 * BioExtract-AI çŠ¶æ€ç®¡ç† Store (API Version)
 * ä½¿ç”¨åç«¯ API æ›¿ä»£æœ¬åœ° SQLite
 */

import { create } from 'zustand';
import type {
    AgentSession,
    AgentMessage,
    ProcessLogEntry,
} from '../types';
import {
    getLLMConfig,
    buildSystemPrompt,
    syncProviders,
    syncSystemSettings,
    type LLMConfig,
    type ChatMessage
} from '../api/llmService';
import { bioextractAPI } from '../api/bioextractAPI';
import {
    BioExtractAgent,
    type ThinkingStep,
} from '../agent';

// =============================================
// é…ç½®å¸¸é‡
// =============================================
const MAX_CONVERSATION_HISTORY = 20; // æœ€å¤§ä¿ç•™çš„å¯¹è¯è½®æ•°

// =============================================
// State æ¥å£å®šä¹‰
// =============================================
interface BioExtractState {
    // ä¼šè¯çŠ¶æ€
    session: AgentSession | null;
    isProcessing: boolean;
    isDataLoading: boolean;

    // LLM é…ç½®
    llmConfig: LLMConfig | null;
    llmConfigured: boolean;
    conversationHistory: ChatMessage[];

    // åç«¯æ•°æ®ç»Ÿè®¡ (æ–°å¢)
    backendStats: {
        delivery_systems_count: number;
        micro_features_count: number;
        paper_tags_count: number;
        atps_records_count: number;
        last_updated: string | null;
    } | null;
    backendConnected: boolean;

    // çŸ¥è¯†åº“æ•°æ® (æ–‡çŒ®å’Œææ–™)
    knowledgeStats: {
        totalDocuments: number;
        totalMaterials: number;
    } | null;

    // å¤„ç†æ—¥å¿—
    processLog: ProcessLogEntry[];
    showProcessLog: boolean;

    // Agent æ€è€ƒè¿‡ç¨‹
    thinkingSteps: ThinkingStep[];
    isThinking: boolean;
    showThinking: boolean;
    agentInstance: BioExtractAgent | null;

    // Actions
    initSession: () => Promise<void>;
    endSession: () => void;
    setLLMConfig: (config: LLMConfig) => void;
    loadBackendStats: () => Promise<void>;
    loadKnowledgeStats: () => Promise<void>;  // æ–°å¢: åŠ è½½æ–‡çŒ®+ææ–™ç»Ÿè®¡

    // æ¶ˆæ¯æ“ä½œ
    addUserMessage: (content: string) => void;
    addAgentMessage: (content: string, metadata?: AgentMessage['metadata'], thinkingSteps?: ThinkingStep[]) => void;
    addSystemMessage: (content: string) => void;

    // Agent è°ƒç”¨ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰
    sendToAgent: (userMessage: string) => Promise<void>;

    // æ€è€ƒè¿‡ç¨‹æ“ä½œ
    addThinkingStep: (step: ThinkingStep) => void;
    clearThinkingSteps: () => void;
    toggleThinking: () => void;

    // æ—¥å¿—æ“ä½œ
    addLogEntry: (type: ProcessLogEntry['type'], content: string, details?: Record<string, unknown>) => void;
    toggleProcessLog: () => void;
    clearProcessLog: () => void;
}

// =============================================
// Store å®ç°
// =============================================
export const useBioExtractStore = create<BioExtractState>((set, get) => ({
    // åˆå§‹çŠ¶æ€
    session: null,
    isProcessing: false,
    isDataLoading: false,

    llmConfig: null,
    llmConfigured: false,
    conversationHistory: [],

    databaseStatus: null, // deprecated but kept for compatibility

    // åç«¯çŠ¶æ€
    backendStats: null,
    backendConnected: false,

    lastQueryResult: null,
    lastQuerySQL: '',

    // çŸ¥è¯†åº“æ•°æ®ç»Ÿè®¡
    knowledgeStats: null,

    processLog: [],
    showProcessLog: true,

    thinkingSteps: [],
    isThinking: false,
    showThinking: true,
    agentInstance: null,

    // ========== åç«¯ API è°ƒç”¨ (æ–°å¢) ==========

    loadBackendStats: async () => {
        try {
            const stats = await bioextractAPI.getStats();
            set({
                backendStats: stats,
                backendConnected: true,
            });
            get().addLogEntry('info', `>>> BACKEND CONNECTED: ${stats.delivery_systems_count} delivery, ${stats.micro_features_count} micro, ${stats.paper_tags_count} tags`);
        } catch (error) {
            set({ backendConnected: false });
            get().addLogEntry('warning', `>>> BACKEND UNAVAILABLE: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    },

    loadKnowledgeStats: async () => {
        try {
            const stats = await bioextractAPI.getKnowledgeStats();
            set({
                knowledgeStats: {
                    totalDocuments: stats.totalDocuments,
                    totalMaterials: stats.totalMaterials,
                },
            });
            get().addLogEntry('result', `>>> KNOWLEDGE: ${stats.totalDocuments} documents, ${stats.totalMaterials} materials`);
        } catch (error) {
            get().addLogEntry('warning', `>>> KNOWLEDGE STATS UNAVAILABLE: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    },

    // ========== ä¼šè¯ç”Ÿå‘½å‘¨æœŸ ==========

    initSession: async () => {
        // å…ˆåŒæ­¥åç«¯ providers åˆ°æœ¬åœ°ç¼“å­˜
        await syncProviders();
        await syncSystemSettings();

        const savedConfig = getLLMConfig();

        const session: AgentSession = {
            id: `session-${Date.now()}`,
            startTime: new Date(),
            status: 'idle',
            steps: [],
            messages: [],
            currentRecommendations: [],
        };

        set({
            session,
            llmConfig: savedConfig,
            llmConfigured: !!savedConfig?.apiKey,
            conversationHistory: [],
            processLog: [],
            isDataLoading: true,
        });

        get().addLogEntry('info', '>>> SESSION INITIALIZED');
        get().addLogEntry('info', '>>> CONNECTING TO BACKEND...');

        try {
            // å¼‚æ­¥åŠ è½½åç«¯ç»Ÿè®¡ (ä¸é˜»å¡ä¸»æµç¨‹)
            await Promise.all([
                get().loadBackendStats(),
                get().loadKnowledgeStats()
            ]);

            // åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ (ä½¿ç”¨é™æ€ Schema)
            const dataContext = buildBackendContext();
            const systemPrompt = buildSystemPrompt(dataContext);

            set({
                conversationHistory: [{ role: 'system', content: systemPrompt }],
                isDataLoading: false,
            });

            // è¾“å‡ºæ¬¢è¿ä¿¡æ¯
            const { backendConnected, backendStats, knowledgeStats } = get();
            let welcomeMsg = '';
            if (backendConnected) {
                welcomeMsg += `âœ… åç«¯è¿æ¥æˆåŠŸã€‚\nå·²åŠ è½½ BioExtract æ•°æ® (${(backendStats?.delivery_systems_count || 0) + (backendStats?.micro_features_count || 0)} æ¡è®°å½•)ã€‚`;
            } else {
                welcomeMsg += `âš ï¸ è¿æ¥åç«¯å¤±è´¥ã€‚è¯·æ£€æŸ¥åç«¯æœåŠ¡ (Port 8001) å’Œ MongoDB çŠ¶æ€ã€‚`;
            }
            if (knowledgeStats) {
                welcomeMsg += `\nğŸ“š çŸ¥è¯†åº“åŒ…å« ${knowledgeStats.totalDocuments} ç¯‡æ–‡çŒ®å’Œ ${knowledgeStats.totalMaterials} ç§ææ–™ã€‚`;
            } else {
                welcomeMsg += `\nâš ï¸ çŸ¥è¯†åº“ç»Ÿè®¡æ•°æ®åŠ è½½å¤±è´¥ã€‚`;
            }

            get().addSystemMessage(welcomeMsg);

        } catch (error) {
            const errorMsg = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
            get().addLogEntry('warning', `>>> INIT ERROR: ${errorMsg}`);
            set({ isDataLoading: false });
            get().addSystemMessage(`âŒ åˆå§‹åŒ–å¤±è´¥ï¼š${errorMsg}`);
        }
    },

    endSession: () => {
        set({
            session: null,
            conversationHistory: [],
            processLog: [],
            thinkingSteps: []
        });
    },

    setLLMConfig: (config: LLMConfig) => {
        set({
            llmConfig: config,
            llmConfigured: !!config.apiKey,
        });

        // é‡æ–°æ„å»ºç³»ç»Ÿæç¤ºè¯ä»¥ç¡®ä¿ä¸Šä¸‹æ–‡æœ€æ–°
        const dataContext = buildBackendContext();
        const systemPrompt = buildSystemPrompt(dataContext);
        set({
            conversationHistory: [{ role: 'system', content: systemPrompt }],
        });

        get().addLogEntry('info', `>>> LLM CONFIG UPDATED: ${config.provider}/${config.model}`);
    },

    // ========== æ¶ˆæ¯æ“ä½œ ==========

    addUserMessage: (content) => {
        const message: AgentMessage = {
            id: `msg-${Date.now()}`,
            role: 'user',
            content,
            timestamp: new Date(),
        };
        set(state => ({
            session: state.session ? { ...state.session, messages: [...state.session.messages, message] } : null,
        }));
    },

    addAgentMessage: (content, metadata, thinkingSteps) => {
        const message: AgentMessage = {
            id: `msg-${Date.now()}`,
            role: 'agent',
            content,
            timestamp: new Date(),
            metadata,
            thinkingSteps: thinkingSteps && thinkingSteps.length > 0 ? [...thinkingSteps] : undefined,
        };
        set(state => ({
            session: state.session ? { ...state.session, messages: [...state.session.messages, message] } : null,
        }));
    },

    addSystemMessage: (content) => {
        const message: AgentMessage = {
            id: `msg-${Date.now()}`,
            role: 'system',
            content,
            timestamp: new Date(),
        };
        set(state => ({
            session: state.session ? { ...state.session, messages: [...state.session.messages, message] } : null,
        }));
    },

    // ========== Agent æ ¸å¿ƒè°ƒç”¨ (API Version) ==========

    sendToAgent: async (userMessage: string) => {
        const { llmConfig, llmConfigured } = get();

        // å¦‚æœæ²¡é…ç½® LLMï¼Œæç¤ºç”¨æˆ·
        if (!llmConfigured || !llmConfig?.apiKey) {
            get().addAgentMessage(`âš ï¸ **æœªé…ç½® LLM**\nè¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Keyã€‚`);
            return;
        }

        set({
            isProcessing: true,
            isThinking: true,
            thinkingSteps: [],
        });

        get().addLogEntry('command', `>>> AGENT START: "${userMessage.slice(0, 30)}..."`);

        try {
            // å®ä¾‹åŒ– Agentï¼Œç»‘å®šå›è°ƒ
            const agent = new BioExtractAgent(llmConfig, {
                onStep: (step: ThinkingStep) => {
                    console.log('[Store] onStep callback:', step.type, step.content.slice(0, 50));
                    get().addThinkingStep(step);
                    if (step.type !== 'observing') {
                        get().addLogEntry('info', `    [${step.type.toUpperCase()}] ${step.content.slice(0, 60)}...`);
                    }
                },
                onError: (error: Error) => {
                    get().addLogEntry('warning', `>>> AGENT INTERNAL ERROR: ${error.message}`);
                }
            });

            // å‡†å¤‡ä¸Šä¸‹æ–‡ - ç°åœ¨ä½¿ç”¨ API å·¥å…·æè¿°
            const dataContext = buildBackendContext();

            // æ‰§è¡Œ Agent (ReAct å¾ªç¯) - ä¸å†éœ€è¦ executeQueryï¼Œå·¥å…·é€šè¿‡ MCP è°ƒç”¨
            const result = await agent.execute({
                userMessage,
                conversationHistory: get().conversationHistory,
                databaseSchema: dataContext,
            });

            get().addLogEntry('result', `>>> AGENT FINISHED: ${result.totalDuration}ms`);

            // æ›´æ–°å¯¹è¯å†å²
            const newTurn: ChatMessage[] = [
                { role: 'user', content: userMessage },
                { role: 'assistant', content: result.response }
            ];

            const currentHistory = get().conversationHistory;
            const chatMessages = [...currentHistory.filter(m => m.role !== 'system'), ...newTurn];
            const trimmedChat = chatMessages.slice(-(MAX_CONVERSATION_HISTORY * 2));

            // Rebuild system prompt with latest context if needed, then update conversation history
            const newSystemPrompt = buildSystemPrompt(buildBackendContext());
            set({
                conversationHistory: [{ role: 'system', content: newSystemPrompt }, ...trimmedChat],
                agentInstance: agent,
            });

            // UI æ·»åŠ æ¶ˆæ¯ï¼ˆé™„å¸¦æœ¬è½®æ€è€ƒæ­¥éª¤ï¼‰
            const currentThinkingSteps = [...get().thinkingSteps];
            get().addAgentMessage(result.response, {
                processLog: result.thinkingSteps.map(s => `[${s.type}] ${s.content}`)
            }, currentThinkingSteps);

            // æ¸…ç©ºå…¨å±€æ€è€ƒæ­¥éª¤ï¼ˆå·²é™„åŠ åˆ°æ¶ˆæ¯ä¸Šï¼‰
            set({ thinkingSteps: [] });

        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
            get().addLogEntry('warning', `>>> AGENT FATAL: ${errorMessage}`);
            get().addAgentMessage(`âŒ **Agent æ‰§è¡Œå¤±è´¥**\n\n${errorMessage}`);
        }

        set({
            isProcessing: false,
            isThinking: false,
        });
    },

    // ========== è¾…åŠ©çŠ¶æ€æ“ä½œ ==========

    addLogEntry: (type, content, details) => {
        set(state => ({
            processLog: [...state.processLog, { timestamp: new Date(), type, content, details }]
        }));
    },

    toggleProcessLog: () => set(s => ({ showProcessLog: !s.showProcessLog })),
    clearProcessLog: () => set({ processLog: [] }),

    addThinkingStep: (step) => set(s => ({ thinkingSteps: [...s.thinkingSteps, step] })),
    clearThinkingSteps: () => set({ thinkingSteps: [] }),
    toggleThinking: () => set(s => ({ showThinking: !s.showThinking })),

}));

// =============================================
// Helper Functions
// =============================================

function buildBackendContext(): string {
    return `
## æ•°æ®è®¿é—®æ–¹å¼

é€šè¿‡ API å·¥å…·è®¿é—®åç«¯æ•°æ®åº“ï¼Œä¸å†ä½¿ç”¨ SQL æŸ¥è¯¢ã€‚
å¯ç”¨å·¥å…·å·²åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­è¯¦ç»†è¯´æ˜ã€‚

ä¸»è¦æ•°æ®ç±»å‹ï¼š
- ç”Ÿç‰©ææ–™ (biomaterials): delivery_system, microbe
- æ–‡çŒ® (documents): å­¦æœ¯è®ºæ–‡å’Œç ”ç©¶æŠ¥å‘Š
`;
}